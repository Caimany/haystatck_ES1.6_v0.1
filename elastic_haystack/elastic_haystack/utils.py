#! -*- coding:utf-8 -*-__author__ = 'root'import sys,jsonreload(sys)sys.setdefaultencoding('utf8')#from haystack.utils import Highlighter#class BorkHighlighter(Highlighter):#    def render_html(self, highlight_locations=None, start_offset=None, end_offset=None):#        highlighted_chunk = self.text_block[start_offset:end_offset]##        for word in self.query_words:#            highlighted_chunk="XXXX"+highlighted_chunk#            highlighted_chunk = highlighted_chunk.replace(word, 'Bork!')#        return highlighted_chunkfrom django.conf import settingsfrom haystack.backends.elasticsearch_backend import ElasticsearchSearchBackend, ElasticsearchSearchEnginefrom haystack.constants import DEFAULT_OPERATOR, DJANGO_CT, DJANGO_ID, IDimport haystackimport encodingsfrom haystack.utils import get_identifier, get_model_ctSYMBOL='。'class ConfigurableElasticBackend(ElasticsearchSearchBackend):    def __init__(self, connection_alias, **connection_options):        super(ConfigurableElasticBackend, self).__init__(                         connection_alias, **connection_options)        # DEFAULT_ANALYZER = "ik"        user_settings = getattr(settings, 'ELASTICSEARCH_INDEX_SETTINGS')        user_analyzer = getattr(settings, 'ELASTICSEARCH_DEFAULT_ANALYZER')        self.tag=0        if user_settings:            setattr(self, 'DEFAULT_SETTINGS', user_settings)        if user_analyzer:            setattr(self, 'DEFAULT_ANALYZER', user_analyzer)    def build_schema(self, fields):        content_field_name, mapping = super(ConfigurableElasticBackend,                                              self).build_schema(fields)        for field_name, field_class in fields.items():            field_mapping = mapping[field_class.index_fieldname]            if field_mapping['type'] == 'string' and field_class.indexed:                if not hasattr(field_class, 'facet_for') and not \                                  field_class.field_type in('ngram', 'edge_ngram'):                    field_mapping['analyzer'] = self.DEFAULT_ANALYZER            mapping.update({field_class.index_fieldname: field_mapping})        return (content_field_name, mapping)    def build_search_kwargs(self, query_string, sort_by=None, start_offset=0, end_offset=None,                            fields='', highlight=False, facets=None,                            date_facets=None, query_facets=None,                            narrow_queries=None, spelling_query=None,                            within=None, dwithin=None, distance_point=None,                            models=None, limit_to_registered_models=None,                            result_class=None):        # fuzzy = kwargs.pop('fuzzy', False)        # fuzzy_field = kwargs.pop('min_similarity', '')        super(ConfigurableElasticBackend,self).build_search_kwargs(                query_string, sort_by,start_offset, end_offset,                            fields, highlight, facets,                            date_facets, query_facets,                            narrow_queries, spelling_query,                            within, dwithin, distance_point,                            models, limit_to_registered_models,                            result_class)        # print json.dumps(search_kwargs)        index = haystack.connections[self.connection_alias].get_unified_index()        content_field = index.document_field        kwargs = {	    'min_score': 0,            'query': {                'query_string': {                    'default_field': content_field,                    'default_operator': DEFAULT_OPERATOR,                    'query': query_string,                    'analyze_wildcard': True,                    'auto_generate_phrase_queries': False,                },            },        }        # so far, no filters        filters = []        if fields:            if isinstance(fields, (list, set)):                fields = " ".join(fields)            kwargs['fields'] = fields        if sort_by is not None:            order_list = []            for field, direction in sort_by:                if field == 'distance' and distance_point:                    # Do the geo-enabled sort.                    lng, lat = distance_point['point'].get_coords()                    sort_kwargs = {                        "_geo_distance": {                            distance_point['field']: [lng, lat],                            "order": direction,                            "unit": "km"                        }                    }                else:                    if field == 'distance':                        warnings.warn("In order to sort by distance, you must call the '.distance(...)' method.")                    # Regular sorting.                    sort_kwargs = {field: {'order': direction}}                order_list.append(sort_kwargs)            kwargs['sort'] = order_list        # From/size offsets don't seem to work right in Elasticsearch's DSL. :/        # if start_offset is not None:        #     kwargs['from'] = start_offset        # if end_offset is not None:        #     kwargs['size'] = end_offset - start_offset        if query_facets is not None:            kwargs.setdefault('facets', {})            for facet_fieldname, value in query_facets:                kwargs['facets'][facet_fieldname] = {                    'query': {                        'query_string': {                            'query': value,                        }                    },                }        if limit_to_registered_models is None:            limit_to_registered_models = getattr(settings, 'HAYSTACK_LIMIT_TO_REGISTERED_MODELS', True)        if models and len(models):            model_choices = sorted(get_model_ct(model) for model in models)        elif limit_to_registered_models:            # Using narrow queries, limit the results to only models handled            # with the current routers.            model_choices = self.build_models_list()        else:            model_choices = []        if len(model_choices) > 0:            filters.append({"terms": {DJANGO_CT: model_choices}})        # if we want to filter, change the query type to filteres        if filters:            kwargs["query"] = {"filtered": {"query": kwargs.pop("query")}}            if len(filters) == 1:                kwargs['query']['filtered']["filter"] = filters[0]            else:                kwargs['query']['filtered']["filter"] = {"bool": {"must": filters}}        # print json.dumps(kwargs)        return kwargsclass ConfigurableElasticSearchEngine(ElasticsearchSearchEngine):    backend = ConfigurableElasticBackendfrom haystack.utils import Highlighterfrom django.utils.html import strip_tagsclass MyHighlighter(Highlighter):    def highlight(self, text_block):        self.text_block = strip_tags(text_block)        highlight_locations = self.find_highlightable_words()        start_offset, end_offset = self.find_window(highlight_locations)        # this is my only edit here, but you'll have to experiment        start_offset = 0        return self.render_html(highlight_locations, start_offset, end_offset)from haystack.utils import Highlighterdef find_symbol(text_block):    word_positions = {}    # Pre-compute the length.    end_offset = len(text_block)    lower_text_block = text_block.lower()    for word in ['。', '\n']:        if not word in word_positions:            word_positions[word] = []        start_offset = 0        while start_offset < end_offset:            next_offset = lower_text_block.find(word, start_offset, end_offset)            # If we get a -1 out of find, it wasn't found. Bomb out and            # start the next word.            if next_offset == -1:                break            word_positions[word].append(next_offset)            start_offset = next_offset + len(word)    symbol_location_list=word_positions[SYMBOL]    symbol_location_list.insert(0,0)    symbol_location_list.insert(-1,len(text_block))    symbol_location_list.sort()    return symbol_location_listclass CustomHighlighter(Highlighter):    def render_html(self, highlight_locations=None, start_offset=None, end_offset=None):        # Start by chopping the block down to the proper window.        text = self.text_block[start_offset:end_offset]        # Invert highlight_locations to a location -> term list        term_list = []        for term, locations in highlight_locations.items():            term_list += [(loc - start_offset, term) for loc in locations]        loc_to_term = sorted(term_list)        # Prepare the highlight template        if self.css_class:            hl_start = '<%s class="%s">' % (self.html_tag, self.css_class)        else:            hl_start = '<%s>' % (self.html_tag)        hl_end = '</%s>' % self.html_tag        # Copy the part from the start of the string to the first match,        # and there replace the match with a highlighted version.        highlighted_chunk = ""        matched_so_far = 0        prev = 0        prev_str = ""        for cur, cur_str in loc_to_term:            # This can be in a different case than cur_str            actual_term = text[cur:cur + len(cur_str)]            # Handle incorrect highlight_locations by first checking for the term            if actual_term.lower() == cur_str:                if cur < prev + len(prev_str):                    continue                highlighted_chunk += text[prev + len(prev_str):cur] + hl_start + actual_term + hl_end                prev = cur                prev_str = cur_str                # Keep track of how far we've copied so far, for the last step                matched_so_far = cur + len(actual_term)        # Don't forget the chunk after the last term        highlighted_chunk += text[matched_so_far:]        symbol_location_list = find_symbol(self.text_block)        # print highlight_locations.items()        start_offset_ext=start_offset        end_offset_ext=end_offset        for i in range(0, len(symbol_location_list)-1):            # if  symbol_location_list[i] < start_offset:            #     print symbol_location_list[i],symbol_location_list[i+1],"%%%%"            if symbol_location_list[i+1]>start_offset:                    start_offset_ext = symbol_location_list[i]                    end_offset_ext = symbol_location_list[i + 1]                    break        if start_offset-start_offset_ext>50:            start_offset_ext=start_offset-50        if end_offset_ext-end_offset>50:            end_offset_ext=end_offset+50        if end_offset_ext>end_offset:            highlighted_chunk=self.text_block[start_offset_ext:start_offset]+highlighted_chunk        else:            highlighted_chunk=self.text_block[start_offset_ext:start_offset]+highlighted_chunk+self.text_block[end_offset:end_offset_ext]        if start_offset_ext > 0:            highlighted_chunk = '。。%s' % highlighted_chunk        if end_offset_ext < len(self.text_block):            highlighted_chunk = '%s。。。' % highlighted_chunk        return highlighted_chunk